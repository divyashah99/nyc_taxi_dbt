name: dbt CI

on:
  push:
    branches: [ master ]
  pull_request:

env:
  DBT_GOOGLE_KEYFILE: /tmp/google/google-service-account.json
  
  # the contents of the keyfile pulled from GitHub Actions secrets 
  KEYFILE_CONTENTS: ${{secrets.GCP_SERVICE_ACCOUNT_KEY}}
  GCP_PROJECT_ID: ${{ secrets.GCP_PROJECT_ID }}
  GCS_BUCKET_NAME: ${{ secrets.GCS_BUCKET_NAME }}

jobs:
  dbt-build:
    runs-on: ubuntu-latest

    steps:
      # 1 Check out repo
      - uses: actions/checkout@v3

            # Prep Google keyfile
      - run: mkdir -p "$(dirname $DBT_GOOGLE_KEYFILE)" 
      - run: echo "$KEYFILE_CONTENTS" > $DBT_GOOGLE_KEYFILE

      # 2 Set up Python
      - uses: actions/setup-python@v4
        with:
          python-version: 3.11

      # 3 Install dbt‑bigquery
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install "dbt-core~=1.10.0" "dbt-bigquery~=1.10.0"

      # 4 Write GCP credentials from secret
      # - name: Write GCP credentials
      #   run: |
      #     mkdir -p "${HOME}"
      #     # Write the secret content to the file
      #     echo "${{ secrets.GCP_SERVICE_ACCOUNT_KEY }}" > "${HOME}/gcp-creds.json"

       

      # 5 Run dbt
      - name: Run dbt
        run: |
          dbt deps
          dbt seed --profiles-dir . --target dev
          dbt run  --profiles-dir . --target dev
          dbt test --profiles-dir . --target dev


       # 6. Generate dbt docs
      - name: Generate dbt docs
        run: |
          dbt docs generate --profiles-dir . --target dev

      # 7. Upload docs to GCS
      - name: Upload docs to GCS
        run: |
          pip install --quiet google-cloud-storage
          python - <<EOF
          from google.cloud import storage
          import os

          client = storage.Client.from_service_account_json(os.environ['DBT_GOOGLE_KEYFILE'])
          bucket = client.bucket(os.environ['GCS_BUCKET_NAME'])

          doc_folder = 'target'
          for root, dirs, files in os.walk(doc_folder):
              for file in files:
                  local_path = os.path.join(root, file)
                  rel_path = os.path.relpath(local_path, doc_folder)
                  blob = bucket.blob(f'dbt-docs/{rel_path}')
                  blob.upload_from_filename(local_path)
                  print(f'Uploaded {rel_path}')